* Current Tasks

** TODO Read the LPD & ROAD papers(do the necessary calculations)and figure out a strategy to establish our result

*** Notion of sparsity, how to measure? When will it preserve?

*** DONE Read Fan's main theorem proof
    CLOSED: [2015-03-28 Sat 14:10] SCHEDULED: <2015-03-21 Sat>
*** Exponential inequalities
Need to figure out how the inequalites in lemma 1 were derived in
LPD paper.

**** Berstein Inequality(2 types of conditions)

*** Obtain similar results like (26) and (27) in LPD paper

*** DONE Uniqueness of the LPD estimator
CLOSED: [2015-11-15 Sun 18:43]
*** TODO prove LPD type asymptotics results for correlation matrices
**** do not expect better results than the covariance matrix version, but in practice use the correlation version is better
** comparison of our algorithm with related algorithms like LPD & ROAD
*** what is the pros & cons?

*** TODO Can LPD select the best marginal feature? How about ROAD? [1/2]
when the tuning parameter is near lambda_max, L0 norm = 1 implies the best
marginal feature is in the active set
**** DONE study whether whenever L0 norm = 1, the nonzero feature is the best marginal feature
     CLOSED: [2015-09-09 Wed 16:33] SCHEDULED: <2015-08-28 Fri>
The answer is no, counter example exists.
**** TODO try to find counter example for covariance matrix via simulation construction

*** piecewise lineararity of the LPD problem & uniqueness

**** DONE professor Lee Dicker's Danzig Selector uniqueness reference
CLOSED: [2015-11-18 Wed 16:13]
** implementation of our algorithm

*** DONE nonsingular case
    CLOSED: [2015-08-15 Sat 14:06]

*** TODO singular case
    SCHEDULED: <2015-12-04 Fri>

** TODO Analyze leukemia data
*** Original dataset vs golub dataset in mulltest package?
No conflict, since I found the script which the autors of mulltest used to
preprocess the data into the *golub* dataset in their package.
*** current issues
**** Sig is not p.d., how to get an initial solution
***** DONE idea
      CLOSED: [2015-09-18 Fri 10:41] SCHEDULED: <2015-05-15 Fri>
Use the objective function in section 4 of ROAD paper, write it in
regression form then apply lars pacakge to solve an initial solution
for a lambda>0.
**** modify the algorithm for the case with singular Sig matrix
The current update method relies on the invertibility of the active
set covariance matrix.
***** TODO Q: when will the solution be unique when Sig is singular?
Not easy at current stage
      SCHEDULED: <2015-05-16 Sat>
***** DONE When Sig is singular, starting from an initial solution, how to update the optimal solutions and subgradients?
      CLOSED: [2015-04-16 Thu 16:26] SCHEDULED: <2015-04-08 Wed>
For gamma1 vector, it is easy. But for gamma2 vector, how to choose
it?
***** Any matrix decomposition package available in R, matlab?
**** p>3000, computation is slow in R
*** Weighted case vs Equal weight case
**** idea
Read the code of ROAD and see whether we could modify it to use in the
weighted scenario.
*** TODO Cross Validation
How to do CV for the current problem?
** TODO Find other implementation code of CLASSO to compare
*** Matlab version for ROAD
*** Tony Cai's LPD
**** DONE Find/write code to solve the LP problem in the paper
     CLOSED: [2015-07-21 Tue 11:40] SCHEDULED: <2015-05-14 Thu>
** TODO study two version of *Partial Least Square*
** complexity results [1/2]
*** DONE one constrain lasso(classo special case)
CLOSED: [2016-02-14 Sun 23:03]
*** TODO LPD
* Current needed background/technique/skill
** convex optimization(like l0,l1,l2...), KKT condition
*** Langrange Multiplier Theory
to the extent that I can derive the all the dual problems in the
recent papers I read(ROAD,Cai,LARS,etc) swiftly

know how to derive dual form and solve langrange multiplier equations
**** Duality and Application
*** gradient descent & stochastic gradient descent(SGD)
** analysis
*** basic skills
*** real & functional analysis
*** matrix analysis
** inequalities
*** elementary inequality
*** norm inequality
*** concentration inequality
** asymptotics
*** familiarize with the rate of convergence language
** bayesian
*** BDA book
focus on the examples and the computation chapters
* Previous work
** Classo Project Special Case

*** DONE Algorithm
    CLOSED: [2015-02-11 Wed 18:42]

*** DONE Matrix Update
    CLOSED: [2015-02-11 Wed 18:42]


*** Algorithm Check
**** Whether the current version is correct
like stopping rule
**** DONE LARS package implementation
   CLOSED: [2015-02-20 Fri 15:14]
using the lars package, for p=4, the number of pieces doesn't meet the expected 42
* Temporary aside
** TODO Think about how to apply our algorithm in classification
** TODO Think about how to modify the algorithm for extension
** estimation of conditional heteroscedastic time series
* Long Term Improvement
** habit of solving problems
** habit of make abstraction, combination & generalization
* Fun Things Learned
** Asymptotic equivalence between White Noise Model & Nonparametric Regression
A fun reading experience with professor Zhang's regression project notes
* Thoughts compilation
** Tao of learning
*** motivation
If you really wanna learn something, always find/generate the *motivation*
first! Then spending enough time/efforts/good communications with others(if possible)
should follow.
*** time, squeeze time!
no skill can be developed without enough time
read and think about Peter Norvig's intriguing article *learn programming in 10
years* .
*** find the right/good questions and direction
*** find the right/good circle to discuss and learn
*** build your knowledge/skill tree from in some systematic way(like using a few but good book in the field)
*** be avid to solve problems, accumulate problem solving strategies in the field you're interested in(same as in life)
keep notes in a timely manner
*** keep thinking, possibly everyday!
*** be brave to focus, to compromise, to make trade-off, to give up
** Research Habits
*** save time & squeeze time
**** ban wechat moments, news checking, etc
**** avoid unnecessary meet and appointment
**** prepare good breakfast, eat quick lunck
*** time analysis
Mon - Wed: 5 hours at night
Thur - Friday: 12 hours per day
Saturday: 9 hours
Sunday: 10 hours

Total: 46 hours/week
Deduction: Sep-Oct, 6 hours lecture preparing per week
*** improve related problem solving skill
as often as possible, better be everyday
**** TODO math/stat problem solving
      SCHEDULED: <2015-09-18 Fri 22:30-23:30 +2d>
      :PROPERTIES:
      :LAST_REPEAT: [2016-02-29 Mon 00:54]
      :END:
      - State "DONE"       from "TODO"       [2016-02-29 Mon 00:54]
**** TODO programming problem solving
     SCHEDULED: <2015-09-29 Tue 22:30-23:30 +2d>
     :PROPERTIES:
     :LAST_REPEAT: [2016-03-04 Fri 12:51]
     :END:
     - State "DONE"       from "TODO"       [2016-03-04 Fri 12:51]
     - State "DONE"       from "TODO"       [2016-02-29 Mon 00:54]
     - State "DONE"       from "TODO"       [2016-02-26 Fri 21:45]
     - State "DONE"       from "TODO"       [2016-02-23 Tue 15:53]
*** express/organize your learning and finding in timely manner, through onenote/org/latex, etc
*** back up your findings(notes and script) in a timely manner
**** using github
currently I'm maintaining backup repositories for my org, lyx and research r
scripts on github.
*** find projects to challenge yourself in timely manner

** on thesis
*** Take initiative & Communicate Efficiently
**** if stuck when trying to prove sth, try find help
Consider people like Boss Xiao, Shetou, Chunhong, Feng Long, Li Qian
Also consider the internet community
**** find more chances to talk to Boss Xiao
Try to do twice a week, like on Wednesday afternoon
*** Practise *mental calculation*
*** Work hard & consistently
*** Persistently improve on the related math skills
I definitely could improve my Matrix Calculus & Matrix Analysis Skills to a much higher level!!!
*** Aha & Crystal Clear Moments!
*** Two Trinities: "Body, Skill, Heart", "Math, Stat, Programming"
*** What results have you got?
**** written down formally?
***** the ROAD exact algorithm for nonsingular case
***** a result of best marginal feature
**** scratch or in mind
***** counter example for best marginal feature
***** algorithm for singular covariance matrix
*** What results are you currently aiming to obtain?
**** easy ones
***** uniqueness of the LPD
**** hard ones
***** LPD asymptotics results for correlation matrices
*** Any idea about extension/generalization?
*** Idea about data analysis?
*** Have the results necessary for a paper? How to organize them?
** Stage thoughts
*** 2.14
1. squeeze time to think about research everyday this year!
2. your focus shall not be more than two at a time
3. gain is accompanied by loss
**** focus
***** thesis
****** LPD asymptotics
***** job skill
****** data mining review
***** job information
** build your knowledge & skill trees on a few but good books/projects/tools/community groups
*** Stat [0/4]
**** TODO ESL
**** TODO Theory of Multivariate Statistics by Bilodeau & Brenner
**** Statistical Learning with Sparsity
**** TODO Time Series by Brockwell
**** TODO Essentials of Stochastic Finance
*** Math & Prob [0/3]
**** TODO Concentration Inequalities by Lugosi
**** TODO Principle of Math Analysis, Rudin
**** TODO Tao's probability course notes & book on random matrix 
*** Programming [0/4]
**** TODO SICP(with *the little scheme* as reference)
**** TODO C++ primer
**** Intro to Algorithm
**** TODO Algorithm Design Manual
**** TODO Algorithm by Dasgupta
**** Code Complete
**** The Pragmatic Programmer
**** The Linux Command Line
*** Projects [0/3]
**** TODO leetcode
**** Codewar Kata
**** SICP problems
**** Github Blog(to maintain actively)
**** TODO Data Mining Hw problems revisit
**** TODO Cracking the code interview problems
**** Finish the remaining Python problems in edx MIT 6.001 Course
*** Tools [0/4]
**** Emacs and Vim
***** Org mode
***** Helm & Magit
**** Git & Github
**** TODO Regular Expressions
**** TODO Latex & TeXmacs
**** TODO Edx & Coursera
**** Google Scholar
**** TODO SQL
**** Spark, Scala, Clojure
**** Jekyll, Markdown & other Web tools
*** Discussion/Community Groups [0/3]
**** TODO SICP and Emacs qq group
**** Emacs Google+ group
**** TODO Codewar & Kaggle
**** StackOverflow
**** Zhihu Programming Language group
**** TODO Some Friends, Fellow Students & Mentor
* Thesis Writing [1/2]
** DONE Gradually export the texmacs version of the CLASSO notes to a latex version
CLOSED: [2016-03-04 Fri 12:50]
Done by modify some export options inside Texmacs
** TODO finish the notes on best marginal feature property for correlation version LPD
*** the counter example

** Communication with advisor
*** Meet Memos
**** 2.14
1. make progress on LPD asymptotics, don't expect better result than covariance version
2. finish the notes on best marginal feature
*** TODO discuss thesis and graduation with advisor
* Challenge Plan
** 9.14 - 9.24 [1/3]
*** DONE primal dual problems examples
     CLOSED: [2015-09-30 Wed 15:11]
*** TODO how can you generalize the sign pattern method for proving piecewise linearity
*** TODO the homotopy idea
** 11.18 - 12.1 [1/2]
*** DONE write down the uniqueness proof for LPD
CLOSED: [2015-12-16 Wed 19:22]
*** TODO Study Lagrangian Duality Theory and accumlate more examples
** 12.16 - 12.23 [2/4]

*** TODO read the concentration inequality section of Tao's random matrix book
*** DONE read the recent two latex notes
CLOSED: [2016-01-29 Fri 18:19]
*** revise CV
*** DONE think about professor Zhang's 663 second project
CLOSED: [2015-12-19 Sat 21:05]
** 1.4 - 1.7 [1/1]
*** DONE finish the pdf notes on LPD uniqueness
CLOSED: [2016-02-14 Sun 22:43]
** 1.29 - 2.3 [1/2]
*** DONE study Ch2 of Lugosi's *concentration inequality* book, exclude the problem section
CLOSED: [2016-02-14 Sun 22:41]
*** TODO study causal inference & structural models
**** think about how to model time dependent treatment data in survival problem context
**** search related R packages
** 2.14 - 2.18 [0/3]
*** TODO study & try to reproduce the proof of Theorem 2 in the LPD paper
SCHEDULED: <2016-02-15 Mon>

*** TODO LPD asymptotics for correlation matrices
**** how to formulate the problem correctly
**** what types of inequality do I need
**** formulate & prove the inequality on tail probability of correlation terms

** Future
*** Improve general coding & simulation technique

**** TODO R problems, hard section
SCHEDULED: <2016-02-15 Mon>
*** TODO Rethink/Restudy some fundamental stat methods and try to summarize in my own words
**** Typical questions to be asked
***** Derivation, Estimation(point type & C.I. type), Testing, Interpretation
***** When to use it?
***** How do you think about it?
**** TODO Logistic Regression
SCHEDULED: <2016-01-31 Sun>
**** Bootstrap Method
**** PCA & Factor Models
**** EM algorithm
**** two versions of Partial Least Square
*** ATE(average treatment effects) estimation literature review [0/3]
**** TODO why use *regression adjustment* ?
**** TODO study the simulation part of professor Zhang's 2015 paper on Lasso adjustment of ATE
**** TODO solve the ATE project main problem in professor Zhang's 663 course in 2015 Fall
